<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Course Project
  | ECE, Virginia Tech | Fall 2025: ECE 4554/5554</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>Proposal: Real vs. AI Generated Images</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Will Fete and Jason Albanus</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2025 ECE 4554/5554 Computer Vision: Course Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Virginia Tech</span>
<hr>

<!-- Abstract -->
<h3>Abstract</h3>
abstract and then teaser figure (2 sentences)
<br><br>
<!-- Introduction -->
<h3>Introduction</h3>
The recent creation of highly realistic, AI-generated synthetic media presents a new challenge in distinguishing between AI and real images. These AI-generated images have a high potential for malicious use, like disinformation campaigns and fraud. This makes it critical to be able to automatically detect AI-generated images. This project aims to address this issue using a deep learning solution to classify images as real or fake. A convolutional neural network (CNN) will be used to do this because of its success with image analysis and feature extraction. The CNN utilizes a series of convolutional layers to extract spatial features and learn the underlying statistical differences and distinguish between real and AI-generated images.


<!-- Approach -->
<h3>Approach</h3>
  Our goal was to build a binary classifier to tell AI-images from real photos. We tried two separate approaches based on our experience with CNNs.
First was a simple custom CNN, second was a transfer-learned ResNet18 variant. For the data, we chose a Kaggle dataset containing a large number of real and AI-generated images.
After loading the images from the train/test folders, resizing them to 224x224, normalizing them to ImageNet statistics, and adding horizontal-flip augmentation to the training data.
Our training loop consists of CrossEntropy loss, an SGD optimizer with a learning rate of 0.001 and a momentum of 0.9, and a batch size of 64 images. 
Throughout the training process, we set it up to output loss and accuracy so we can monitor them.
	For our first model, the simple CNN, it consisted of a 3-block structure with convolution, batch normalization, ReLU, and max pooling. Then it had two fully connected layers with dropout 
to classify into the two classes. Additionally, we used an SGD optimizer with momentum. This, combined with dropout, helped to reduce overfitting. Our other model uses ResNet18 with ImageNet-pretrained weights.
We swap the final fully connected layer for a 2-class head and fine-tune using our dataset. Similar to the simple CNN, we used the same dataloader, transforms, loss, optimizer, and batch size. To determine 
how the CNN performed, we ran it on the test data and measured its accuracy. Additionally, for the final model we chose, we generated a confusion matrix. Finally, we built a small Tkinter app that loads the 
saved weights, runs the same transforms, and shows the predicted label with confidence for any uploaded image.
  Our training and evaluation loops were adapted from our ECE 4554 homework.

<br><br>
<!--Experiments-->
<h3>Experiments and Results</h3>
also include qualitative results
<br><br>

<!--Conclusion-->
<h3>Conclusion</h3>
This report has described the need for differentiating between real and AI-generated images, and proposed a solution using deep learning techniques. The threat of malicious AI-generated images is real, and we proposed a way to help mitigate that. Our proposed solution gave both a simple CNN, similar to what was worked on in class, and a ResNet18 variant model. With very high levels of accuracy, balanced precision and recall scores, and a high F1-Score, it is clear that both of the approaches are good at not only classifying real and fake images, but also are not biased towards false positives or false negatives. This is really important when dealing with automatic detection where you don’t want to mark real images as AI-generated, while also not marking AI-generated images as real. While the results were very good, there are some potential improvements to the project and the approach. The current dataset is based on CIFAR-10, which does not have the best quality of images, despite scaling them up to 224x224. This means that the models may struggle with high quality AI-generated images that are more prevalent with recent advances in AI. This problem could be addressed with a new dataset with these newer AI-generated images, but as AI continues to improve and evolve, the methods to detect and prevent malicious use of it must do the same.
<br><br>

<h3>References</h3>
<ol>
  <li>
    J. J. Bird and A. Lotfi, "CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images," in <em>IEEE Access</em>, vol. 12, pp. 15642-15650, 2024, doi: 10.1109/ACCESS.2024.3356122.
  </li>
  <li>
    IBM, “Convolutional Neural Networks,” <em>IBM</em>, Oct. 06, 2021. [Online]. Available: <a href="https://www.ibm.com/topics/convolutional-neural-networks">https://www.ibm.com/topics/convolutional-neural-networks</a>
  </li>
  <li>
    A. Krizhevsky, “Learning multiple layers of features from tiny images,” University of Toronto, Tech. Rep., 2009.
  </li>
</ol>
  <hr>
  <footer> 
  <p>© Will Fete and Jason Albanus</p>
  </footer>
</div>
</div>

<br><br>

</body></html>
