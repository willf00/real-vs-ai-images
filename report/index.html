<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Course Project
  | ECE, Virginia Tech | Fall 2025: ECE 4554/5554</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>Proposal: Real vs. AI Generated Images</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Will Fete and Jason Albanus</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2025 ECE 4554/5554 Computer Vision: Course Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Virginia Tech</span>
<hr>

<!-- Abstract -->
<h3>Abstract</h3>
abstract and then teaser figure (2 sentences)
<br><br>
<!-- Introduction -->
<h3>Introduction</h3>
Introduction

<!-- Approach -->
<h3>Approach</h3>
  Our goal was to build a binary classifier to tell AI-images from real photos. We tried two separate approaches based on our experience with CNNs.
First was a simple custom CNN, second was a transfer-learned ResNet18 variant. For the data, we chose a Kaggle dataset containing a large number of real and AI-generated images.
After loading the images from the train/test folders, resizing them to 224x224, normalizing them to ImageNet statistics, and adding horizontal-flip augmentation to the training data.
Our training loop consists of CrossEntropy loss, an SGD optimizer with a learning rate of 0.001 and a momentum of 0.9, and a batch size of 64 images. 
Throughout the training process, we set it up to output loss and accuracy so we can monitor them.
	For our first model, the simple CNN, it consisted of a 3-block structure with convolution, batch normalization, ReLU, and max pooling. Then it had two fully connected layers with dropout 
to classify into the two classes. Additionally, we used an SGD optimizer with momentum. This, combined with dropout, helped to reduce overfitting. Our other model uses ResNet18 with ImageNet-pretrained weights.
We swap the final fully connected layer for a 2-class head and fine-tune using our dataset. Similar to the simple CNN, we used the same dataloader, transforms, loss, optimizer, and batch size. To determine 
how the CNN performed, we ran it on the test data and measured its accuracy. Additionally, for the final model we chose, we generated a confusion matrix. Finally, we built a small Tkinter app that loads the 
saved weights, runs the same transforms, and shows the predicted label with confidence for any uploaded image.
  Our training and evaluation loops were adapted from our ECE 4554 homework.

<br><br>
<!--Experiments-->
<h3>Experiments and Results</h3>
also include qualitative results
<br><br>

<!--Conclusion-->
<h3>Conclusion</h3>
conclusion
<br><br>

<h3>References</h3>
<ol>
  <li>
    J. J. Bird and A. Lotfi, "CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images," in <em>IEEE Access</em>, vol. 12, pp. 15642-15650, 2024, doi: 10.1109/ACCESS.2024.3356122.
  </li>
  <li>
    IBM, “Convolutional Neural Networks,” <em>IBM</em>, Oct. 06, 2021. [Online]. Available: <a href="https://www.ibm.com/topics/convolutional-neural-networks">https://www.ibm.com/topics/convolutional-neural-networks</a>
  </li>
  <li>
    A. Krizhevsky, “Learning multiple layers of features from tiny images,” University of Toronto, Tech. Rep., 2009.
  </li>
</ol>
  <hr>
  <footer> 
  <p>© Will Fete and Jason Albanus</p>
  </footer>
</div>
</div>

<br><br>

</body></html>
